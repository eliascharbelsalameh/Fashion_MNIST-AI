{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-31cByaLyWhw",
        "outputId": "4d74d7bc-9f6c-414b-bde3-802533be58e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       pixel1  pixel2  pixel3  pixel4  pixel5    pixel6  pixel7  pixel8  \\\n",
            "0         0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0   \n",
            "1         0.0     0.0     0.0     0.0     0.0  0.003922     0.0     0.0   \n",
            "2         0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0   \n",
            "3         0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0   \n",
            "4         0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0   \n",
            "...       ...     ...     ...     ...     ...       ...     ...     ...   \n",
            "69995     0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0   \n",
            "69996     0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0   \n",
            "69997     0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0   \n",
            "69998     0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0   \n",
            "69999     0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0   \n",
            "\n",
            "         pixel9   pixel10  ...  pixel775  pixel776  pixel777  pixel778  \\\n",
            "0      0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
            "1      0.000000  0.000000  ...  0.466667  0.447059  0.509804  0.298039   \n",
            "2      0.000000  0.086275  ...  0.000000  0.000000  0.003922  0.000000   \n",
            "3      0.129412  0.376471  ...  0.000000  0.000000  0.000000  0.000000   \n",
            "4      0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
            "...         ...       ...  ...       ...       ...       ...       ...   \n",
            "69995  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
            "69996  0.000000  0.121569  ...  0.000000  0.000000  0.000000  0.000000   \n",
            "69997  0.000000  0.000000  ...  0.105882  0.000000  0.000000  0.000000   \n",
            "69998  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
            "69999  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
            "\n",
            "       pixel779  pixel780  pixel781  pixel782  pixel783  pixel784  \n",
            "0           0.0       0.0       0.0       0.0       0.0       0.0  \n",
            "1           0.0       0.0       0.0       0.0       0.0       0.0  \n",
            "2           0.0       0.0       0.0       0.0       0.0       0.0  \n",
            "3           0.0       0.0       0.0       0.0       0.0       0.0  \n",
            "4           0.0       0.0       0.0       0.0       0.0       0.0  \n",
            "...         ...       ...       ...       ...       ...       ...  \n",
            "69995       0.0       0.0       0.0       0.0       0.0       0.0  \n",
            "69996       0.0       0.0       0.0       0.0       0.0       0.0  \n",
            "69997       0.0       0.0       0.0       0.0       0.0       0.0  \n",
            "69998       0.0       0.0       0.0       0.0       0.0       0.0  \n",
            "69999       0.0       0.0       0.0       0.0       0.0       0.0  \n",
            "\n",
            "[70000 rows x 784 columns]\n",
            "[9 0 0 ... 8 1 5]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Load MNIST data from openml\n",
        "fashion_mnist = fetch_openml('Fashion-MNIST') # mnist_784\n",
        "X = fashion_mnist.data / 255.0  # Scale pixel values to [0, 1]\n",
        "y = np.array(fashion_mnist.target, dtype=int)\n",
        "print(X)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of features is:  784\n",
            "The number of samples is:  70000\n",
            "The dimension of X is:  (70000, 784)\n"
          ]
        }
      ],
      "source": [
        "print(\"The number of features is: \",X.shape[1])\n",
        "print(\"The number of samples is: \",X.shape[0])\n",
        "print(\"The dimension of X is: \",X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEVLZ7C61H4l",
        "outputId": "919261ef-953a-41ca-eea5-9f5b12f8f458"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.51264637\n",
            "Iteration 2, loss = 0.36435090\n",
            "Iteration 3, loss = 0.32347036\n",
            "Iteration 4, loss = 0.30406966\n",
            "Iteration 5, loss = 0.28086744\n",
            "Iteration 6, loss = 0.26907840\n",
            "Iteration 7, loss = 0.25304010\n",
            "Iteration 8, loss = 0.24328878\n",
            "Iteration 9, loss = 0.23253601\n",
            "Iteration 10, loss = 0.21939006\n",
            "Iteration 11, loss = 0.21028643\n",
            "Iteration 12, loss = 0.20375298\n",
            "Iteration 13, loss = 0.19834338\n",
            "Iteration 14, loss = 0.18396445\n",
            "Iteration 15, loss = 0.17824996\n",
            "Iteration 16, loss = 0.17462542\n",
            "Iteration 17, loss = 0.16149563\n",
            "Iteration 18, loss = 0.16009783\n",
            "Iteration 19, loss = 0.15219431\n",
            "Iteration 20, loss = 0.14818660\n",
            "Iteration 21, loss = 0.14279730\n",
            "Iteration 22, loss = 0.13568001\n",
            "Iteration 23, loss = 0.12964684\n",
            "Iteration 24, loss = 0.12412798\n",
            "Iteration 25, loss = 0.12206602\n",
            "Iteration 26, loss = 0.11764703\n",
            "Iteration 27, loss = 0.11570488\n",
            "Iteration 28, loss = 0.10850466\n",
            "Iteration 29, loss = 0.10607219\n",
            "Iteration 30, loss = 0.10295949\n",
            "Iteration 31, loss = 0.09647691\n",
            "Iteration 32, loss = 0.09346038\n",
            "Iteration 33, loss = 0.08666613\n",
            "Iteration 34, loss = 0.08372590\n",
            "Iteration 35, loss = 0.09001055\n",
            "Iteration 36, loss = 0.08500268\n",
            "Iteration 37, loss = 0.07917250\n",
            "Iteration 38, loss = 0.07803998\n",
            "Iteration 39, loss = 0.08281387\n",
            "Iteration 40, loss = 0.07035650\n",
            "Iteration 41, loss = 0.06826885\n",
            "Iteration 42, loss = 0.06941414\n",
            "Iteration 43, loss = 0.06691277\n",
            "Iteration 44, loss = 0.06518658\n",
            "Iteration 45, loss = 0.05609155\n",
            "Iteration 46, loss = 0.05669797\n",
            "Iteration 47, loss = 0.06197887\n",
            "Iteration 48, loss = 0.06319790\n",
            "Iteration 49, loss = 0.06238849\n",
            "Iteration 50, loss = 0.05757736\n",
            "Iteration 51, loss = 0.05038959\n",
            "Iteration 52, loss = 0.04410232\n",
            "Iteration 53, loss = 0.04987062\n",
            "Iteration 54, loss = 0.05081125\n",
            "Iteration 55, loss = 0.05348141\n",
            "Iteration 56, loss = 0.05163729\n",
            "Iteration 57, loss = 0.04497298\n",
            "Iteration 58, loss = 0.04379796\n",
            "Iteration 59, loss = 0.03560535\n",
            "Iteration 60, loss = 0.04438221\n",
            "Iteration 61, loss = 0.04678068\n",
            "Iteration 62, loss = 0.04045621\n",
            "Iteration 63, loss = 0.04660330\n",
            "Iteration 64, loss = 0.03622277\n",
            "Iteration 65, loss = 0.03882455\n",
            "Iteration 66, loss = 0.04223354\n",
            "Iteration 67, loss = 0.04245957\n",
            "Iteration 68, loss = 0.04490282\n",
            "Iteration 69, loss = 0.03089982\n",
            "Iteration 70, loss = 0.03108346\n",
            "Iteration 71, loss = 0.03418310\n",
            "Iteration 72, loss = 0.03671066\n",
            "Iteration 73, loss = 0.03449245\n",
            "Iteration 74, loss = 0.03790863\n",
            "Iteration 75, loss = 0.03711825\n",
            "Iteration 76, loss = 0.02952226\n",
            "Iteration 77, loss = 0.02931881\n",
            "Iteration 78, loss = 0.03665593\n",
            "Iteration 79, loss = 0.03027270\n",
            "Iteration 80, loss = 0.02968127\n",
            "Iteration 81, loss = 0.02659590\n",
            "Iteration 82, loss = 0.03948406\n",
            "Iteration 83, loss = 0.02727297\n",
            "Iteration 84, loss = 0.03260940\n",
            "Iteration 85, loss = 0.02836959\n",
            "Iteration 86, loss = 0.02843672\n",
            "Iteration 87, loss = 0.02989809\n",
            "Iteration 88, loss = 0.01780911\n",
            "Iteration 89, loss = 0.03861433\n",
            "Iteration 90, loss = 0.02471355\n",
            "Iteration 91, loss = 0.01968715\n",
            "Iteration 92, loss = 0.03941532\n",
            "Iteration 93, loss = 0.01912692\n",
            "Iteration 94, loss = 0.02992083\n",
            "Iteration 95, loss = 0.02960254\n",
            "Iteration 96, loss = 0.01979922\n",
            "Iteration 97, loss = 0.03463665\n",
            "Iteration 98, loss = 0.02079060\n",
            "Iteration 99, loss = 0.02968828\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Train set accuracy: 99.36\n",
            "Test set accuracy: 90.14\n"
          ]
        }
      ],
      "source": [
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create MLPClassifier model with desired hyperparameters\n",
        "model = MLPClassifier(hidden_layer_sizes=(512,512,128,), activation='relu', solver='adam', max_iter=300, verbose=True)\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the testing data\n",
        "accuracy_train = model.score(X_train,y_train)\n",
        "accuracy_test = model.score(X_test, y_test)\n",
        "print(\"Train set accuracy: {:.2f}\".format(accuracy_train * 100))\n",
        "print(\"Test set accuracy: {:.2f}\".format(accuracy_test * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "m2cKRlUZ7DsL",
        "outputId": "5e867b6f-9f70-4706-9989-2b4d7bd2111b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6639 - loss: 0.9094\n",
            "Epoch 2/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8554 - loss: 0.4018\n",
            "Epoch 3/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8795 - loss: 0.3336\n",
            "Epoch 4/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8916 - loss: 0.2977\n",
            "Epoch 5/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9032 - loss: 0.2692\n",
            "313/313 - 0s - 1ms/step - accuracy: 0.8897 - loss: 0.3075\n",
            "Test accuracy: 0.8896999955177307\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "\n",
        "# Load MNIST dataset\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Preprocess input images\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "train_images = train_images.astype('float32') / 255.0\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "test_images = test_images.astype('float32') / 255.0\n",
        "\n",
        "# Define model architecture\n",
        "model = keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=128)\n",
        "\n",
        "# Evaluate model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "print(f'Test accuracy: {test_acc}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 841
        },
        "id": "oXg3aQcuLvgp",
        "outputId": "a78442c0-ecb4-4ac3-9ce2-edd60ec72c38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\elias\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Found array with dim 4. MLPClassifier expected <= 2.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[17], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(indices)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Make predictions on the test set\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m y_pred_logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_pred_logits, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Create a figure with 16 subplots\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\elias\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1159\u001b[0m, in \u001b[0;36mMLPClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict using the multi-layer perceptron classifier.\u001b[39;00m\n\u001b[0;32m   1147\u001b[0m \n\u001b[0;32m   1148\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;124;03m    The predicted classes.\u001b[39;00m\n\u001b[0;32m   1157\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m-> 1159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\elias\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1163\u001b[0m, in \u001b[0;36mMLPClassifier._predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m   1161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Private predict method with optional input validation\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1163\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_pass_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1166\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39mravel()\n",
            "File \u001b[1;32mc:\\Users\\elias\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:207\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._forward_pass_fast\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict using the trained model\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03mThis is the same as _forward_pass but does not record the activations\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m    The decision function of the samples for each class in the model.\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_input:\n\u001b[1;32m--> 207\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;66;03m# Initialize first layer\u001b[39;00m\n\u001b[0;32m    210\u001b[0m activation \u001b[38;5;241m=\u001b[39m X\n",
            "File \u001b[1;32mc:\\Users\\elias\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
            "File \u001b[1;32mc:\\Users\\elias\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1043\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1039\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1040\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1041\u001b[0m     )\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m-> 1043\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1044\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1045\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1046\u001b[0m     )\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m   1049\u001b[0m     _assert_all_finite(\n\u001b[0;32m   1050\u001b[0m         array,\n\u001b[0;32m   1051\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m   1052\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m   1053\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1054\u001b[0m     )\n",
            "\u001b[1;31mValueError\u001b[0m: Found array with dim 4. MLPClassifier expected <= 2."
          ]
        }
      ],
      "source": [
        "# Get 16 random indices for the test set\n",
        "#indices = np.random.choice(len(test_images), size=16, replace=False)\n",
        "#indices = np.where(np.random.rand(len(test_images)) < 0.025)[0]\n",
        "indices = [1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039]\n",
        "print(indices)\n",
        "# Make predictions on the test set\n",
        "y_pred_logits = model.predict(test_images[indices])\n",
        "y_pred = np.argmax(y_pred_logits, axis=-1)\n",
        "\n",
        "# Create a figure with 16 subplots\n",
        "fig, axs = plt.subplots(nrows=4, ncols=4, figsize=(10, 8))\n",
        "\n",
        "# For each subplot, plot the corresponding image and write the true and predicted labels on top\n",
        "for i, ax in enumerate(axs.flatten()):\n",
        "    if i < len(indices):\n",
        "        img_index = indices[i]\n",
        "        ax.imshow(test_images[img_index], cmap='gray')\n",
        "        ax.set_title(f'T: {test_labels[img_index]}, P: {y_pred[i]}', fontsize=12)\n",
        "        ax.axis('off')\n",
        "\n",
        "#for i, ax in zip(indices, axs.flatten()):\n",
        "#    ax.imshow(test_images[i], cmap='gray')\n",
        "    #ax.set_title(f'True: {test_labels[i]}, Pred: {y_pred[i]}', fontsize=12)\n",
        "#    ax.set_title(f'T {test_labels[i]}, P {y_pred[i]}', fontsize=12)\n",
        "#    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
